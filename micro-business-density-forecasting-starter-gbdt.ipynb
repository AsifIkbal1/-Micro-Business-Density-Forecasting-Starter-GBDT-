{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸŒ‡ GoDaddy - Microbusiness Density Forecasting\n### Forecast Next Monthâ€™s Microbusiness Density\n\n\n<img src='https://miro.medium.com/max/1400/1*gsUixexI9DsFfKsS-ZZqng.webp' width = 750>\n\n### Overview...\nThe main goal is to develop a simple notebook utilizing GDBTs to construct a Machine Learning Model...\n\n---\n\n### Dataset Description\nYour challenge in this competition is to forecast microbusiness activity across the United States, as measured by the density of microbusinesses in US counties. Microbusinesses are often too small or too new to show up in traditional economic data sources, but microbusiness activity may be correlated with other economic indicators of general interest.\n\nAs historic economic data are widely available, this is a forecasting competition. The forecasting phase public leaderboard and final private leaderboard will be determined using data gathered after the submission period closes. You will make static forecasts that can only incorporate information available before the end of the submission period.\n\n**Files**\n\nA great deal of data is publicly available about counties and we have not attempted to gather it all here. You are strongly encouraged to use external data sources for features.\n\ntrain.csv\n\n* row_id - An ID code for the row.\n* cfips - A unique identifier for each county using the Federal Information Processing System. The first two digits correspond to the state FIPS code, while the following 3 represent the county.\n* county_name - The written name of the county.\n* state_name - The name of the state.\n* first_day_of_month - The date of the first day of the month.\n* microbusiness_density - Microbusinesses per 100 people over the age of 18 in the given county. This is the target variable. The population figures used to calculate the density are on a two-year lag due to the pace of update provided by the U.S. Census Bureau, which provides the underlying population data annually. 2021 density figures are calculated using 2019 population figures, etc.\n* active - The raw count of microbusinesses in the county. Not provided for the test set.\n\n**sample_submission.csv** \n\nA valid sample submission. This file will remain unchanged throughout the competition.\n\n* row_id - An ID code for the row.\n* microbusiness_density - The target variable.\n\n**test.csv** \n\nMetadata for the submission rows. This file will remain unchanged throughout the competition.\n\n* row_id - An ID code for the row.\n* cfips - A unique identifier for each county using the Federal Information Processing System. The first two digits correspond to the state FIPS code, while the following 3 represent the county.\n* first_day_of_month - The date of the first day of the month.\n* revealed_test.csv During the submission period, only the most recent month of data will be used for the public leaderboard. Any test set data older than that will be published in revealed_test.csv, closely following the usual data release cycle for the microbusiness report. We expect to publish one copy of revealed_test.csv in mid * February. This file's schema will match train.csv.\n\n**census_starter.csv**\n\nExamples of useful columns from the Census Bureau's American Community Survey (ACS) at data.census.gov. The percentage fields were derived from the raw counts provided by the ACS. All fields have a two year lag to match what information was avaiable at the time a given microbusiness data update was published.\n\n* pct_bb_[year] - The percentage of households in the county with access to broadband of any type. Derived from ACS table B28002: PRESENCE AND TYPES OF INTERNET SUBSCRIPTIONS IN HOUSEHOLD.\n* cfips - The CFIPS code.\n* pct_college_[year] - The percent of the population in the county over age 25 with a 4-year college degree. Derived from ACS table S1501: EDUCATIONAL ATTAINMENT.\n* pct_foreign_born_[year] - The percent of the population in the county born outside of the United States. Derived from ACS table DP02: SELECTED SOCIAL CHARACTERISTICS IN THE UNITED STATES.\n* pct_it_workers_[year] - The percent of the workforce in the county employed in information related industries. Derived from ACS table S2405: INDUSTRY BY OCCUPATION FOR THE CIVILIAN EMPLOYED POPULATION 16 YEARS AND OVER.\n* median_hh_inc_[year] - The median household income in the county. Derived from ACS table S1901: INCOME IN THE PAST 12 MONTHS (IN 2021 INFLATION-ADJUSTED DOLLARS.\n---","metadata":{}},{"cell_type":"markdown","source":"# 1.0 Loading All Nesesary Libraries","metadata":{}},{"cell_type":"code","source":"%%time\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-26T23:39:53.853258Z","iopub.execute_input":"2022-12-26T23:39:53.853748Z","iopub.status.idle":"2022-12-26T23:39:53.863571Z","shell.execute_reply.started":"2022-12-26T23:39:53.853709Z","shell.execute_reply":"2022-12-26T23:39:53.862216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Loading more libraries for the model...\nfrom pathlib import Path # OS path library...\nfrom sklearn.preprocessing import LabelEncoder # Label encoding...","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:53.86993Z","iopub.execute_input":"2022-12-26T23:39:53.87036Z","iopub.status.idle":"2022-12-26T23:39:53.878358Z","shell.execute_reply.started":"2022-12-26T23:39:53.870325Z","shell.execute_reply":"2022-12-26T23:39:53.877009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Load model libraries...\nfrom xgboost import XGBRegressor # GBDT Library, XGBosst Regressor\nfrom catboost import CatBoostRegressor # GBDT Library, CatBoost Regressor\n\n# Load Sklearn libraries...\nfrom sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor # Regressors\n\nfrom sklearn.metrics import mean_squared_error # Load metrics\nfrom sklearn.model_selection import StratifiedKFold, TimeSeriesSplit, GroupKFold, KFold # Load CV strategies\nfrom sklearn.preprocessing import LabelEncoder # Load encoder packages\n\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder # Load Normalization libraries\nfrom sklearn.pipeline import Pipeline # Load sklearn pipelines, in case are needed in the CV loop\nfrom sklearn.compose import ColumnTransformer # Load \n\nimport holidays # Holiday libraries\nimport matplotlib.pyplot as plt # Visualization libraries","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:53.880939Z","iopub.execute_input":"2022-12-26T23:39:53.881456Z","iopub.status.idle":"2022-12-26T23:39:53.890083Z","shell.execute_reply.started":"2022-12-26T23:39:53.881419Z","shell.execute_reply":"2022-12-26T23:39:53.888818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 2.0 Notebook Configuration\nPlaceholder, explanations of this sections...","metadata":{}},{"cell_type":"code","source":"%%time\n# I like to disable my Notebook Warnings.\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:53.891137Z","iopub.execute_input":"2022-12-26T23:39:53.891439Z","iopub.status.idle":"2022-12-26T23:39:53.905417Z","shell.execute_reply.started":"2022-12-26T23:39:53.891412Z","shell.execute_reply":"2022-12-26T23:39:53.904415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Notebook Configuration...\n\n# Amount of data we want to load into the Model...\nDATA_ROWS = None\n# Dataframe, the amount of rows and cols to visualize...\nNROWS = 50\nNCOLS = 15\n# Main data location path...\nBASE_PATH = '...'","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:53.906799Z","iopub.execute_input":"2022-12-26T23:39:53.907997Z","iopub.status.idle":"2022-12-26T23:39:53.917183Z","shell.execute_reply.started":"2022-12-26T23:39:53.907912Z","shell.execute_reply":"2022-12-26T23:39:53.916083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Configure notebook display settings to only use 2 decimal places, tables look nicer.\npd.options.display.float_format = '{:,.2f}'.format\npd.set_option('display.max_columns', NCOLS) \npd.set_option('display.max_rows', NROWS)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:53.919577Z","iopub.execute_input":"2022-12-26T23:39:53.920503Z","iopub.status.idle":"2022-12-26T23:39:53.928156Z","shell.execute_reply.started":"2022-12-26T23:39:53.920466Z","shell.execute_reply":"2022-12-26T23:39:53.926894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 3.0 Loading the Datasets into a Pandas DataFrame\nPlaceholder, explanations of this sections...","metadata":{}},{"cell_type":"code","source":"%%time\n# Load the CSV information into a Pandas DataFrame...\ninput_path = Path('/kaggle/input/godaddy-microbusiness-density-forecasting/')\n\ntrain_df = pd.read_csv(input_path / 'train.csv')\ncensus_df = pd.read_csv(input_path / 'census_starter.csv')\ntest_df = pd.read_csv(input_path / 'test.csv')\n\nsubmission = pd.read_csv(input_path / 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:53.92949Z","iopub.execute_input":"2022-12-26T23:39:53.929948Z","iopub.status.idle":"2022-12-26T23:39:54.203132Z","shell.execute_reply.started":"2022-12-26T23:39:53.929915Z","shell.execute_reply":"2022-12-26T23:39:54.201873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.205696Z","iopub.execute_input":"2022-12-26T23:39:54.206774Z","iopub.status.idle":"2022-12-26T23:39:54.221931Z","shell.execute_reply.started":"2022-12-26T23:39:54.20672Z","shell.execute_reply":"2022-12-26T23:39:54.220748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint('Min:',train_df['first_day_of_month'].min())\nprint('Max:',train_df['first_day_of_month'].max())","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.223709Z","iopub.execute_input":"2022-12-26T23:39:54.224232Z","iopub.status.idle":"2022-12-26T23:39:54.251616Z","shell.execute_reply.started":"2022-12-26T23:39:54.224187Z","shell.execute_reply":"2022-12-26T23:39:54.250275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unpivot the Census information...\ncensus_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.252797Z","iopub.execute_input":"2022-12-26T23:39:54.253386Z","iopub.status.idle":"2022-12-26T23:39:54.276348Z","shell.execute_reply.started":"2022-12-26T23:39:54.253355Z","shell.execute_reply":"2022-12-26T23:39:54.275077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nvariables = [var for var in census_df.columns if var not in ['cfips']]\ncensus_unpivot = pd.melt(census_df, id_vars = 'cfips', value_vars = variables)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.278202Z","iopub.execute_input":"2022-12-26T23:39:54.279094Z","iopub.status.idle":"2022-12-26T23:39:54.295551Z","shell.execute_reply.started":"2022-12-26T23:39:54.279044Z","shell.execute_reply":"2022-12-26T23:39:54.294676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncensus_unpivot","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.298542Z","iopub.execute_input":"2022-12-26T23:39:54.298903Z","iopub.status.idle":"2022-12-26T23:39:54.314452Z","shell.execute_reply.started":"2022-12-26T23:39:54.29887Z","shell.execute_reply":"2022-12-26T23:39:54.31344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncensus_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.315834Z","iopub.execute_input":"2022-12-26T23:39:54.316891Z","iopub.status.idle":"2022-12-26T23:39:54.341766Z","shell.execute_reply.started":"2022-12-26T23:39:54.316852Z","shell.execute_reply":"2022-12-26T23:39:54.3407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncensus_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.34513Z","iopub.execute_input":"2022-12-26T23:39:54.346214Z","iopub.status.idle":"2022-12-26T23:39:54.353895Z","shell.execute_reply.started":"2022-12-26T23:39:54.346158Z","shell.execute_reply":"2022-12-26T23:39:54.352751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.355462Z","iopub.execute_input":"2022-12-26T23:39:54.356133Z","iopub.status.idle":"2022-12-26T23:39:54.368868Z","shell.execute_reply.started":"2022-12-26T23:39:54.356078Z","shell.execute_reply":"2022-12-26T23:39:54.368097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntest_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.370663Z","iopub.execute_input":"2022-12-26T23:39:54.371717Z","iopub.status.idle":"2022-12-26T23:39:54.381286Z","shell.execute_reply.started":"2022-12-26T23:39:54.371673Z","shell.execute_reply":"2022-12-26T23:39:54.380502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Min:',test_df['first_day_of_month'].min())\nprint('Max:',test_df['first_day_of_month'].max())","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.38236Z","iopub.execute_input":"2022-12-26T23:39:54.382798Z","iopub.status.idle":"2022-12-26T23:39:54.394465Z","shell.execute_reply.started":"2022-12-26T23:39:54.382768Z","shell.execute_reply":"2022-12-26T23:39:54.393375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.397892Z","iopub.execute_input":"2022-12-26T23:39:54.398651Z","iopub.status.idle":"2022-12-26T23:39:54.411393Z","shell.execute_reply.started":"2022-12-26T23:39:54.398602Z","shell.execute_reply":"2022-12-26T23:39:54.410038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 4.0 Preparing the Information for Analysis\nPlaceholder, explanations of this sections...","metadata":{}},{"cell_type":"code","source":"%%time\naux_info = train_df[['cfips', 'county','state']]\naux_info = aux_info.drop_duplicates()\naux_info.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.446488Z","iopub.execute_input":"2022-12-26T23:39:54.447119Z","iopub.status.idle":"2022-12-26T23:39:54.493062Z","shell.execute_reply.started":"2022-12-26T23:39:54.447083Z","shell.execute_reply":"2022-12-26T23:39:54.491923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef merge_df(first_df, second_df, join_field = ['cfips']) -> pd.DataFrame:\n    '''\n    Merge two pandas datasets...\n    '''\n    merge_df = first_df.merge(second_df, how = 'left', left_on = join_field, right_on = join_field)\n    merge_df.reset_index(inplace = True, drop = True)\n    return merge_df\n\ntrn_data = merge_df(train_df, census_df)\ntst_data = merge_df(test_df, census_df)\ntst_data = merge_df(tst_data, aux_info)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.495314Z","iopub.execute_input":"2022-12-26T23:39:54.496026Z","iopub.status.idle":"2022-12-26T23:39:54.60983Z","shell.execute_reply.started":"2022-12-26T23:39:54.495979Z","shell.execute_reply":"2022-12-26T23:39:54.608706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(trn_data.shape, tst_data.shape)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.611507Z","iopub.execute_input":"2022-12-26T23:39:54.612235Z","iopub.status.idle":"2022-12-26T23:39:54.618086Z","shell.execute_reply.started":"2022-12-26T23:39:54.612191Z","shell.execute_reply":"2022-12-26T23:39:54.617244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrn_data","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.620164Z","iopub.execute_input":"2022-12-26T23:39:54.620726Z","iopub.status.idle":"2022-12-26T23:39:54.696461Z","shell.execute_reply.started":"2022-12-26T23:39:54.620689Z","shell.execute_reply":"2022-12-26T23:39:54.695356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntst_data","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.698096Z","iopub.execute_input":"2022-12-26T23:39:54.698839Z","iopub.status.idle":"2022-12-26T23:39:54.733435Z","shell.execute_reply.started":"2022-12-26T23:39:54.698794Z","shell.execute_reply":"2022-12-26T23:39:54.732356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 5.0 Feature Engineering\nPlaceholder, explanations of this sections...","metadata":{}},{"cell_type":"code","source":"%%time\n# Create some simple features base on the Date field...\n\ndef create_time_features(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Create features base on the date variable, the idea is to extract as much \n    information from the date componets.\n    Args\n        df: Input data to create the features.\n    Returns\n        df: A DataFrame with the new time base features.\n    \"\"\"\n    \n    df['date'] = pd.to_datetime(df['first_day_of_month']) # Convert the date to datetime.\n    \n    # Start the creating future process.\n    df['year'] = df['date'].dt.year\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['day'] = df['date'].dt.day\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['dayofmonth'] = df['date'].dt.days_in_month\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['weekofyear'] = df['date'].dt.weekofyear\n    df['is_weekend'] = np.where((df['dayofweek'] == 5) | (df['dayofweek'] == 6), 1, 0)\n    \n    return df\n\n# Apply the function 'create_time_features' to the dataset...\ntrn_data = create_time_features(trn_data)\ntst_data = create_time_features(tst_data)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.735399Z","iopub.execute_input":"2022-12-26T23:39:54.736157Z","iopub.status.idle":"2022-12-26T23:39:54.938214Z","shell.execute_reply.started":"2022-12-26T23:39:54.736111Z","shell.execute_reply":"2022-12-26T23:39:54.937133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 6.0 Data Pre-Processing\nPlaceholder, explanations of this sections...","metadata":{}},{"cell_type":"code","source":"%%time\n# ...\ndef encode_labels(df, text_features = ['country','store', 'product']):\n    '''\n    Describe the function...\n    '''\n    \n    for categ_col in df[text_features].columns:\n        encoder = LabelEncoder()\n        df[categ_col + '_enc'] = encoder.fit_transform(df[categ_col])\n    return df\n\ntrn_data = encode_labels(trn_data, text_features = ['county','state'])\ntst_data = encode_labels(tst_data, text_features = ['county','state'])","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:54.942055Z","iopub.execute_input":"2022-12-26T23:39:54.942442Z","iopub.status.idle":"2022-12-26T23:39:55.075904Z","shell.execute_reply.started":"2022-12-26T23:39:54.942408Z","shell.execute_reply":"2022-12-26T23:39:55.075131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrn_data['microbusiness_density'].describe()","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:55.077212Z","iopub.execute_input":"2022-12-26T23:39:55.077686Z","iopub.status.idle":"2022-12-26T23:39:55.093908Z","shell.execute_reply.started":"2022-12-26T23:39:55.077655Z","shell.execute_reply":"2022-12-26T23:39:55.092672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 7.0 Features & Data Selection\nPlaceholder, explanations of this sections...","metadata":{}},{"cell_type":"code","source":"%%time\n# Extract features and avoid certain columns from the dataframe for training purposes...\ntarget = 'microbusiness_density'\navoid = ['row_id', 'first_day_of_month','cfips', 'microbusiness_density', 'active', 'county', 'state', 'date']\nfeatures = [feat for feat in trn_data.columns if feat not in avoid]\n\n# Print a list of all the features created...\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:55.095677Z","iopub.execute_input":"2022-12-26T23:39:55.096152Z","iopub.status.idle":"2022-12-26T23:39:55.103096Z","shell.execute_reply.started":"2022-12-26T23:39:55.096111Z","shell.execute_reply":"2022-12-26T23:39:55.10197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Creates the Train and Validation sets to train the model...\n# Define a cutoff date to split the datasets\ncutoff_date = '2021-10-01'\n\n# Split the data into train and validation datasets using timestamp best suited for timeseries...\nX_train = trn_data[trn_data['first_day_of_month'] < cutoff_date][features]\ny_train = trn_data[trn_data['first_day_of_month'] < cutoff_date][target]\n\nX_val = trn_data[trn_data['first_day_of_month'] >= cutoff_date][features]\ny_val = trn_data[trn_data['first_day_of_month'] >= cutoff_date][target]","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:55.104445Z","iopub.execute_input":"2022-12-26T23:39:55.104764Z","iopub.status.idle":"2022-12-26T23:39:55.235203Z","shell.execute_reply.started":"2022-12-26T23:39:55.104734Z","shell.execute_reply":"2022-12-26T23:39:55.234041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#...\ndef SMAPE(y_true, y_pred):\n    '''\n    \n    '''\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:55.236972Z","iopub.execute_input":"2022-12-26T23:39:55.237739Z","iopub.status.idle":"2022-12-26T23:39:55.245928Z","shell.execute_reply.started":"2022-12-26T23:39:55.237691Z","shell.execute_reply":"2022-12-26T23:39:55.243555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 8.0 Development of an GBDT Model (XGBoost)","metadata":{}},{"cell_type":"code","source":"%%time\n# Defines a really simple XGBoost Regressor...\n\nxgboost_params = {'eta'              : 0.01,\n                  'n_estimators'     : 8192,\n                  'max_depth'        : 16,\n                  'max_leaves'       : 256,\n                  'colsample_bylevel': 0.95,\n                  'colsample_bytree' : 0.95,\n                  'subsample'        : 0.95, # XGBoost would randomly sample 'subsample_value' of the training data prior to growing trees\n                  'min_child_weight' : 256,\n                  'min_split_loss'   : 0.002,\n                  'alpha'            : 0.08,\n                  'lambda'           : 64,\n                  'objective'        : 'reg:squarederror',\n                  'eval_metric'      : 'mae', # Originally using RMSE, trying new functions...\n                  'tree_method'      : 'hist',\n                  'seed'             :  42\n                  }","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:55.24707Z","iopub.execute_input":"2022-12-26T23:39:55.247378Z","iopub.status.idle":"2022-12-26T23:39:55.258618Z","shell.execute_reply.started":"2022-12-26T23:39:55.24735Z","shell.execute_reply":"2022-12-26T23:39:55.257368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Create an instance of the XGBRegressor and set the model parameters...\nregressor = XGBRegressor(**xgboost_params)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:55.260181Z","iopub.execute_input":"2022-12-26T23:39:55.260633Z","iopub.status.idle":"2022-12-26T23:39:55.275414Z","shell.execute_reply.started":"2022-12-26T23:39:55.260589Z","shell.execute_reply":"2022-12-26T23:39:55.274133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Train the XGBRegressor using the train and validation datasets, \n# Utilizes early_stopping_rounds to control overfitting...\nregressor.fit(X_train,\n              y_train,\n              eval_set=[(X_val, y_val)],\n              early_stopping_rounds = 250,\n              verbose = 250)","metadata":{"execution":{"iopub.status.busy":"2022-12-26T23:39:55.276543Z","iopub.execute_input":"2022-12-26T23:39:55.276859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9.0 Machine Learning Explainability","metadata":{}},{"cell_type":"code","source":"%%time\n#...\nfeats = {} # a dict to hold feature_name: feature_importance\nfor feature, importance in zip(features, regressor.feature_importances_):\n    feats[feature] = importance # add the name/value pair \n\nimportances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-importance'})\nimportances.sort_values(by='Gini-importance', ascending=False).plot(kind='bar', rot=90, figsize=(10,5))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 10.0 Generating Model Predictions\nPlaceholder, explanations of this sections...","metadata":{}},{"cell_type":"code","source":"%%time\nval_pred = regressor.predict(X_val[features])\n\nscore = np.sqrt(mean_squared_error(y_val, val_pred))\nprint(f'RMSE: {score} / SMAPE: {SMAPE(y_val, val_pred)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%%time\n#...\n# Use the created model to predict the sales for 2019...\npredictions = regressor.predict(tst_data[features])\nsubmission['microbusiness_density'] = predictions\n\n# Creates a submission file for Kaggle...\nsubmission.to_csv('submission.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsubmission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Development of a Linear Regression Model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}}]}